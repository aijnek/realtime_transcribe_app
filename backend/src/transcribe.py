import os
import pyaudio
import asyncio
import numpy as np
from google import genai
from google.genai import types
from dotenv import load_dotenv

load_dotenv()

system_instruction = """
ã‚ãªãŸã¯æ­£ç¢ºãªéŸ³å£°æ–‡å­—èµ·ã“ã—ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚èã“ãˆãŸéŸ³å£°ã‚’æ­£ç¢ºã«æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚
ä¼šè©±ã‚„å¿œç­”ã¯ä¸è¦ã§ã€èã“ãˆãŸå†…å®¹ã‚’æ›¸ãèµ·ã“ã™ã ã‘ã§ã™ã€‚
ãŸã ã—ã€ãˆãƒ¼ã€ã‚ã®ãƒ¼ã€ãªã©ã®ãƒ•ã‚£ãƒ©ãƒ¼éŸ³ã¯å‰Šé™¤ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚
é‡è¤‡ã‚„å†—é•·ãªè¡¨ç¾ãŒã‚ã‚Œã°è‡ªç„¶ãªæ—¥æœ¬èªã«ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚
"""

async def start_transcription(api_key):
    """æ–‡å­—èµ·ã“ã—"""
    
    # Live APIè¨­å®š - æ–‡å­—èµ·ã“ã—å°‚ç”¨ã«æœ€é©åŒ–
    client = genai.Client(api_key=api_key)
    model = "gemini-2.0-flash-live-001"
    config = {
        "response_modalities": ["TEXT"],
        "system_instruction": types.Content(
            parts=[types.Part(text=system_instruction)],
        ),
        "realtime_input_config": {
            "automatic_activity_detection": {
                "disabled": False,
                "start_of_speech_sensitivity": types.StartSensitivity.START_SENSITIVITY_HIGH,
                "end_of_speech_sensitivity": types.EndSensitivity.END_SENSITIVITY_LOW,  # ç™ºè©±çµ‚äº†ã‚’é…ã‚ã«æ¤œå‡º
                "silence_duration_ms": 1500,  # 1.5ç§’æ²ˆé»™ã§çµ‚äº†
                "prefix_padding_ms": 300,  # ç™ºè©±é–‹å§‹å‰ã®éŸ³å£°ã‚‚å«ã‚ã‚‹
            }
        }
    }
    
    # PyAudioè¨­å®š
    audio = pyaudio.PyAudio()
    stream = None
    
    try:
        # ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
        stream = audio.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=16000,
            input=True,
            frames_per_buffer=1600  # 100msåˆ†
        )
        
        print("ğŸ“¢ éŒ²éŸ³ä¸­ã§ã™(10ç§’é–“)...")
        
        async with client.aio.live.connect(model=model, config=config) as session:
            
            total_audio_level = 0
            audio_count = 0
            
            # 10ç§’é–“éŸ³å£°ã‚’éŒ²éŸ³ãƒ»é€ä¿¡
            for i in range(100):  # 100 * 100ms = 10ç§’
                audio_data = stream.read(1600, exception_on_overflow=False)
                
                # éŸ³å£°ãƒ¬ãƒ™ãƒ«ç¢ºèª
                audio_array = np.frombuffer(audio_data, dtype=np.int16)
                level = np.sqrt(np.mean(audio_array**2))
                
                if level > 20:  # ã‚ˆã‚Šä½ã„é–¾å€¤ã§æ¤œå‡º
                    total_audio_level += level
                    audio_count += 1
                    if i % 10 == 0:  # 1ç§’ã”ã¨ã«è¡¨ç¤º
                        print(f"ğŸ¤ éŸ³å£°æ¤œå‡ºä¸­... ãƒ¬ãƒ™ãƒ«: {level:.0f}")
                
                # Live APIã«é€ä¿¡
                await session.send_realtime_input(
                    audio=types.Blob(
                        data=audio_data,
                        mime_type="audio/pcm;rate=16000"
                    )
                )
                
                await asyncio.sleep(0.1)
            
            # å¹³å‡éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’è¡¨ç¤º
            if audio_count > 0:
                avg_level = total_audio_level / audio_count
                print(f"ğŸ“Š å¹³å‡éŸ³å£°ãƒ¬ãƒ™ãƒ«: {avg_level:.0f}")
            else:
                print("âš ï¸  éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            
            print("ğŸ”š éŒ²éŸ³çµ‚äº†ã€å¿œç­”å¾…æ©Ÿä¸­...")
            
            # éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ çµ‚äº†ã‚’é€šçŸ¥
            await session.send_realtime_input(audio_stream_end=True)
            
            # ã‚ˆã‚Šé•·ã„æ™‚é–“å¿œç­”ã‚’å¾…æ©Ÿ
            print("â³ æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­ï¼ˆæœ€å¤§15ç§’å¾…æ©Ÿï¼‰...")
            timeout_count = 0
            all_responses = []
            
            async for response in session.receive():
                timeout_count += 1
                
                if response.text is not None:
                    text = response.text.strip()
                    if text:
                        all_responses.append(text)
                        print(f"ğŸ“ éƒ¨åˆ†çµæœ: {text}")
                
                # ã‚µãƒ¼ãƒãƒ¼ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒã‚§ãƒƒã‚¯
                if hasattr(response, 'server_content') and response.server_content:
                    if hasattr(response.server_content, 'turn_complete') and response.server_content.turn_complete:
                        print("âœ… æ–‡å­—èµ·ã“ã—å®Œäº†")
                        break
                
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (15ç§’)
                if timeout_count > 150:
                    print("â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
                    break
                
                await asyncio.sleep(0.1)
            
            # æœ€çµ‚çµæœã‚’è¡¨ç¤º
            if all_responses:
                final_result = " ".join(all_responses)
                print("=" * 50)
                print(f"ğŸ“„ æœ€çµ‚æ–‡å­—èµ·ã“ã—çµæœ:")
                print(f"'{final_result}'")
                print("=" * 50)
            else:
                print("âŒ æ–‡å­—èµ·ã“ã—çµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒå®šç¾©æ¸ˆã¿ã‹ã¤é–‹ã„ã¦ã„ã‚Œã°åœæ­¢ãƒ»ã‚¯ãƒ­ãƒ¼ã‚º
        if stream is not None:
            try:
                stream.stop_stream()
            except Exception:
                pass
            stream.close()
        # PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è§£æ”¾
        audio.terminate()


# ãƒ¡ã‚¤ãƒ³é–¢æ•°
async def main():
    api_key = os.environ.get("GOOGLE_API_KEY")
    
    if not api_key:
        print("âŒ APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        return
    
    await start_transcription(api_key)

if __name__ == "__main__":
    asyncio.run(main())
